import numpy as np

import sklearn
import sklearn.ensemble
import sklearn.linear_model
import sklearn.svm
import sklearn.tree
import xgboost

from sklearn.metrics import r2_score, max_error, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error

# The keys are the method name according to Scikit-Learn documentation
_MODELS = {
    "SVR": sklearn.svm.SVR(),
    "BaggingRegressor": sklearn.ensemble.BaggingRegressor(),
    "NuSVR": sklearn.svm.NuSVR(),
    "RandomForestRegressor": sklearn.ensemble.RandomForestRegressor(),
    "XGBRegressor": xgboost.XGBRegressor(verbosity=0),
    "GradientBoostingRegressor": sklearn.ensemble.GradientBoostingRegressor(),
    "ExtraTreesRegressor": sklearn.ensemble.ExtraTreesRegressor(),
    "AdaBoostRegressor": sklearn.ensemble.AdaBoostRegressor(),
    "KNeighborsRegressor": sklearn.neighbors.KNeighborsRegressor(),
    "DecisionTreeRegressor": sklearn.tree.DecisionTreeRegressor(),
    "HuberRegressor": sklearn.linear_model.HuberRegressor(),
    "LinearSVR": sklearn.svm.LinearSVR(),
    "RidgeCV": sklearn.linear_model.RidgeCV(),
    "BayesianRidge": sklearn.linear_model.BayesianRidge(),
    "Ridge": sklearn.linear_model.Ridge(),
    "LinearRegression": sklearn.linear_model.LinearRegression(),
    "ElasticNetCV": sklearn.linear_model.ElasticNetCV(),
    "LassoCV": sklearn.linear_model.LassoCV(),
    "LassoLarsIC": sklearn.linear_model.LassoLarsIC(),
    "LassoLarsCV": sklearn.linear_model.LassoLarsCV(),
    "Lars": sklearn.linear_model.Lars(),
    "LarsCV": sklearn.linear_model.LarsCV(),
    "SGDRegressor": sklearn.linear_model.SGDRegressor(),
    "ElasticNet": sklearn.linear_model.ElasticNet(),
    "Lasso": sklearn.linear_model.Lasso(),
    "RANSACRegressor": sklearn.linear_model.RANSACRegressor(),
    "OrthogonalMatchingPursuitCV": sklearn.linear_model.OrthogonalMatchingPursuitCV(),
    "PassiveAggressiveRegressor": sklearn.linear_model.PassiveAggressiveRegressor(),
    "OrthogonalMatchingPursuit": sklearn.linear_model.OrthogonalMatchingPursuit(),
    "ExtraTreeRegressor": sklearn.tree.ExtraTreeRegressor(),
    "DummyRegressor": sklearn.dummy.DummyRegressor(),
    "LassoLars": sklearn.linear_model.LassoLars()
}

_SPACES = {
    "SVR": {'kernel': ['linear', 'rbf', 'sigmoid'],
            'gamma': [0.00001 * pow(10, x) for x in range(10)],
            'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 20000, 30000, 40000, 50000,
                  100000],
            'epsilon': [0.01 * pow(10, x) for x in range(3)]},
    "BaggingRegressor": {'n_estimators': [10, 50, 100, 500, 500, 1000, 5000],
                         'max_samples': np.arange(0.1, 1.1, 0.1)},
    "NuSVR": {'nu': [0.01, 0.05, 0.1, 0.5, 1],
              'kernel': ['linear', 'rbf', 'sigmoid'],
              'gamma': [0.00001 * pow(10, x) for x in range(10)],
              'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 20000, 30000, 40000,
                    50000,
                    100000]},
    "RandomForestRegressor": {'n_estimators': [2, 20, 100, 200, 2000],
                              'criterion': ['mse', 'mae'],
                              'min_samples_split': [int(x) for x in np.linspace(start=2, stop=40, num=5)],
                              'min_samples_leaf': [int(x) for x in np.linspace(start=1, stop=20, num=5)],
                              'max_features': ['auto', 'sqrt', 'log2']},
    "XGBRegressor": {'booster': ["gbtree", "gblinear", "dart"],
                     'learning_rate': [.3, .2, .1, .05, .01, .005]},
    "GradientBoostingRegressor": {'loss': ['ls', 'lad', 'huber', 'quantile'],
                                  'learning_rate': [1, 0.1, 0.01, 0.001],
                                  'n_estimators': [2, 20, 100, 200, 2000],
                                  'subsample': [1, 0.1, 0.01, 0.001],
                                  'criterion': ['mse', 'friedman_mse'],
                                  'min_samples_split': [int(x) for x in np.linspace(start=2, stop=40, num=5)],
                                  'min_samples_leaf': [int(x) for x in np.linspace(start=1, stop=20, num=5)],
                                  'max_features': ['auto', 'sqrt', 'log2']},
    "ExtraTreesRegressor": {'n_estimators': [2, 20, 100, 200, 2000],
                            'criterion': ['mse', 'mae'],
                            'min_samples_split': [int(x) for x in np.linspace(start=2, stop=40, num=5)],
                            'min_samples_leaf': [int(x) for x in np.linspace(start=1, stop=20, num=5)],
                            'max_features': ['auto', 'sqrt', 'log2']},
    "AdaBoostRegressor": {'n_estimators': [50, 100, 200, 500, 1000],
                          'learning_rate': [0.01, 0.05, 0.1, 0.3, 1],
                          'loss': ['linear', 'square', 'exponential']},
    "KNeighborsRegressor": {'n_neighbors': [2, 3, 4, 5, 6],
                            'weights': ['uniform', 'distance'],
                            'algorithm': ["auto", "ball_tree", "kd_tree", "brute"],
                            'metric': ["euclidean", "manhattan", "chebyshev"]},
    "DecisionTreeRegressor": {'criterion': ['mse', 'friedman_mse', 'mae'],
                              'min_samples_split': [int(x) for x in np.linspace(start=2, stop=40, num=5)],
                              'min_samples_leaf': [int(x) for x in np.linspace(start=1, stop=20, num=5)],
                              'max_features': ['auto', 'sqrt', 'log2']},
    "HuberRegressor": {"epsilon": [1, 1.35, 1.5, 2, 5, 10],
                       "max_iter": [10, 100, 500, 1000],
                       "alpha": [0.0001, 0.001, 0.01, 0.1, 1, 10]},
    "LinearSVR": {'loss': ["epsilon_insensitive", "squared_epsilon_insensitive"],
                  'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 20000, 30000, 40000,
                        50000, 100000],
                  'epsilon': [0, 0.01, 0.1, 1]},
    "RidgeCV": {"fit_intercept": [True, False],
                "normalize": [True, False],
                "gcv_mode": ["auto", "svd", "eigen"]},
    "BayesianRidge": {'n_iter': [1, 10, 100, 300, 500, 1000, 5000, 10000, 100000],
                      'alpha_1': [100, 10, 1, 1e-3, 1e-6, 1e-9],
                      'alpha_2': [100, 10, 1, 1e-3, 1e-6, 1e-9],
                      'lambda_1': [100, 10, 1, 1e-3, 1e-6, 1e-9],
                      'lambda_2': [100, 10, 1, 1e-3, 1e-6, 1e-9],
                      'compute_score': [True, False],
                      'fit_intercept': [True, False],
                      'normalize': [True, False],
                      'copy_X': [True, False]},
    "Ridge": {"alpha": [0.1, 1, 10, 100, 500, 1000],
              "fit_intercept": [True, False],
              "normalize": [True, False],
              "solver": ["auto", "svd", "cholesky", "lsqr", "sparse_cg", "sag", "saga"]},
    "LinearRegression": {'fit_intercept': [True, False],
                         'normalize': [True, False],
                         'copy_X': [True, False],
                         'positive': [True, False]},
    "ElasticNetCV": {"l1_ratio": [0, 0.25, 0.5, 0.75, 1],
                     "fit_intercept": [True, False],
                     "normalize": [True, False]},
    "LassoCV": {"fit_intercept": [True, False],
                "normalize": [True, False]},
    "LassoLarsIC": {"criterion": ["bic", "aic"],
                    "fit_intercept": [True, False],
                    "normalize": [True, False]},
    "LassoLarsCV": {"fit_intercept": [True, False],
                    "normalize": [True, False]},
    "Lars": {"fit_intercept": [True, False],
             "normalize": [True, False]},
    "LarsCV": {"fit_intercept": [True, False],
               "normalize": [True, False]},
    "SGDRegressor": {"loss": ["squared_loss", "huber", "epsilon_insensitive", "squared_epsilon_insensitive"],
                     "penalty": ["l1", "l2", "elasticnet"],
                     "alpha": [0.005, 0.02, 0.03, 0.05, 0.06, 0.1, 1, 10, 100, 500, 1000],
                     "l1_ratio": [0, 0.25, 0.5, 0.75, 1],
                     "fit_intercept": [True, False],
                     "learning_rate": ["constant", "optimal", "invscaling", "adaptive"]},
    "ElasticNet": {"alpha": [0.005, 0.02, 0.03, 0.05, 0.06, 0.1, 1, 10, 100, 500, 1000],
                   "l1_ratio": [0, 0.25, 0.5, 0.75, 1],
                   "fit_intercept": [True, False],
                   "normalize": [True, False]},
    "Lasso": {"alpha": [0.005, 0.02, 0.03, 0.05, 0.06, 0.1, 1, 10, 100, 500, 1000],
              "fit_intercept": [True, False],
              "normalize": [True, False]},
    "RANSACRegressor": {"min_samples": [0, 0.1, 0.5, 0.9, 1, 5, 10, 50],
                        "loss": ["absolute_loss", "squared_loss"]},
    "OrthogonalMatchingPursuitCV": {"fit_intercept": [True, False],
                                    "normalize": [True, False]},
    "PassiveAggressiveRegressor": {
        'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 20000, 30000, 40000, 50000,
              100000],
        "fit_intercept": [True, False],
        'epsilon': [0.01 * pow(10, x) for x in range(3)],
    },
    "OrthogonalMatchingPursuit": {"fit_intercept": [True, False],
                                  "normalize": [True, False]},
    "ExtraTreeRegressor": {'criterion': ['mse', 'friedman_mse', 'mae'],
                           'min_samples_split': [int(x) for x in np.linspace(start=2, stop=40, num=5)],
                           'min_samples_leaf': [int(x) for x in np.linspace(start=1, stop=20, num=5)],
                           'max_features': ['auto', 'sqrt', 'log2']},
    "DummyRegressor": {"strategy": ["mean", "median"]
                       },
    "LassoLars": {"alpha": [0.005, 0.02, 0.03, 0.05, 0.06, 0.1, 1, 10, 100, 500, 1000],
                  "fit_intercept": [True, False],
                  "normalize": [True, False]}
}

_METRICS = {
    "max_error": lambda true, pred: max_error(true, pred),
    "mean_absolute_error": lambda true, pred: mean_absolute_error(true, pred),
    "root_mean_squared_error": lambda true, pred: mean_squared_error(true, pred) ** 0.5,
    "mean_absolute_percentage_error": lambda true, pred: mean_absolute_percentage_error(true, pred)
}